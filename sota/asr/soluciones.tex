\subsubsection{Enfoques actuales y soluciones}
EL \textbf{WER} (Word Error Rate) se define de la manera visible en la ecuación \ref{eq:wer}

\begin{equation}\label{eq:wer}
    WER = \frac{S + D + I}{N}
\end{equation}

donde $S$ son las sustituciones (palabras que se confunden con otras), $D$ son los borrados (\textit{deletions}, palabras que no son detectadas), $I$ son las inserciones (palabras que se añaden) y $N$ es el número total de palabras en la grabación original. \textbf{La mejor solución será aquella que consiga el $WER$ más bajo}.

\begin{enumerate}
    \item \textbf{ATCO2 Corpus} \cite{ATCO2_EndToEndCallsignRecognition2021} No es una solución en sí misma: es un ecosistema estandarizado consistente de, a saber, \textit{ATCO2-test-set corpus} y \textit{ATCO2 pseudo-labeled set corpus}. El primero son cuatro horas de transcripciones comprobadas, marcas con el rol del hablante (a modo \texttt{<pilot>...<pilot>}) además de otros \textit{tags} sobre elementos de la comunicación, además de todo lo que contiene el segundo (salvo la duración). El segundo consiste en aproximadamente 5281 horas de audio de control aéreo, con metadatos como puntuación de detección de inglés, puntuaciones de confianza o SNR; datos contextuales y transcripciones con ASR (pueden no ser correctos).

    Actualmente, una semana de trabajo por transcriptores profesionales (controladores aéreos retirados o en activo) equivale a una hora de transcripciones efectivas para poder ser usadas al estándar \textbf{test-set}. Los datos de diferentes aeropuertos difieren por convenciones locales, lo cual dificulta que haya un dominio estandarizados de datos. A nosotros, sin embargo, no nos afecta para nuestra resolución de problemas, pues buscamos aplicar esto a pseudopilotos y no a control aéreo real.

    Antes del \textit{ATCO2 Corpus}, se intentaba entrenar con \textbf{corpora} como Librispeech \cite{panayotov2015librispeech} o TED-LIUM \cite{hernandez2018ted} pero estos \textit{datasets} probaron no ser lo suficientemente `difíciles' como para entrenar a los ASR de ATC.

    Los resultados del entrenamiento se pueden ver en \cite{ATCO2_EndToEndCallsignRecognition2021}. Encontramos que el WER en ATCO2 test set es en torno a 0,22. 
    
    \textbf{PROPUESTA: }Si bien esto no es aceptable para un entorno de control aéreo real, quizá podamos implementar un mejor método para minimizar el WER. Quizá podamos hacer un nuevo corpus complementario al ATCO2 con datos de entrenamiento. También podemos seguir con un modelo de 0,22 teniendo en cuenta que el audio del pseudopiloto va a tener alta fidelidad y confianza, no necesitamos que el WER sea muy grande (y quizá tampoco necesitemos un corpus de entrenamiento especializado).

    \item \textbf{ATCOSIM Corpus}. Se trata de una base de datos de 10 horas de grabaciones ATC. Todo está en ingles y pronunciado por angloparlantes nativos. En este caso, tampoco se trata de una solución al problema sino de un corpus de entrenamiento, quizá útil para validación de un modelo ASR.

    En este punto conviene preguntarse si no existe un corpus en español que nos permita hacer todo esto pero... en español. \textbf{NO EXISTE} un corpus público que sea ad-hoc para ATC en español. Existen bases de datos de corpus generales (\textbf{Mozilla Common Voice} \cite{ardila2020common}, \textbf{VoxPopuli} \cite{wang-etal-2021-voxpopuli})

    \item \textbf{A Virtual Simulation-Pilot Agent for Training of Air Traffic Controllers} \cite{Zuluaga-Gomez2023Virtual} 
    
    \begin{itemize}
        \item \textbf{APUNTE: } no tanto que ver con ASR, pero se asegura que la pipeline se construye solo con Open Source. 
    \end{itemize}

    \textbf{Wav2Vec2.0} es la herramienta usada para el ASR de este artículo. También usan \textbf{XLSR} (\textit{Cross-Language Speech Recognition}). Merece la pena ampliar un poco esta sección y explicar qué son estas dos cosas.
    \begin{itemize}
        \item \textbf{Wav2Vec2.0 [NO RIGUROSO]} \cite{DBLP:journals/corr/abs-2006-11477}. Para entender esta herramienta explico lo que es el aprendizaje semi supervisado. Supongamos que un fragmento de audio está unívocamente determinado por una serie de informaciones auditivas $a_1, a_2, \ldots, a_n$. Digamos que cada uno de los vectores $a_i$ se compone de $m$ componentes (es decir, $a_i \in \mathbb{R}^m)$. Entonces, lo que hacemos es quitar algunos de los fragmentos de audio y dar al modelo a elegir entre ciertas opciones para rellenar el hueco vacío.
        \item \textbf{XLSR} Es una iniciativa por la que se entrena al modelo anterior en múltiples idiomas. Se utiliza \textit{Multilingual LibriSpeech} \cite{Pratap2020MLSAL} como corpus de entrenamiento.
    \end{itemize}
    El \textbf{resultado} consiste
\end{enumerate}
